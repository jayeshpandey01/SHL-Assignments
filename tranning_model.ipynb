{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "test = pd.read_csv(\"dataset/train.csv\")\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "submission = pd.read_csv(\"dataset/sample_submission.csv\")\n",
    "\n",
    "train.head(), submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe Audio \n",
    "* whisper help to accurate and effecient way's to convert speech to text\n",
    "* using whisper medium for more accurate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "def transcribe_audio(audio_path):\n",
    "    if not audio_path:\n",
    "        return 'audio not found'\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"] if result else None\n",
    "\n",
    "train['transcription'] = train['filename'].apply(lambda x: transcribe_audio(f'dataset/audios_train/{x}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Linguistic Features\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.abspath(\"dataset/audios_train/audio_1261.wav\")\n",
    "print(\"Exists?\", os.path.isfile(file_path))\n",
    "print(\"Path used:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/444 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1261.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/444 [00:04<32:19,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_942.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/444 [00:05<16:34,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1110.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/444 [00:05<11:39,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1024.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/444 [00:07<10:33,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_538.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/444 [00:08<11:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_350.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6/444 [00:10<12:32,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/444 [00:12<11:58,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_252.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/444 [00:20<26:20,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1304.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/444 [00:22<21:59,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1230.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/444 [00:23<18:19,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_133.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/444 [00:24<15:57,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_790.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/444 [00:25<12:59,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_947.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/444 [00:31<21:21,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_288.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/444 [00:35<23:54,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1111.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/444 [00:40<26:27,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_771.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 16/444 [00:42<23:44,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1184.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 17/444 [00:45<22:14,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_918.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 18/444 [00:49<24:48,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1030.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/444 [00:53<25:12,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1112.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 20/444 [00:57<27:12,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_873.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 21/444 [01:03<30:54,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_539.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 22/444 [01:08<31:56,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_899.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 23/444 [01:12<29:47,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1277.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 24/444 [01:16<31:04,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_649.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 25/444 [01:18<25:53,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_701.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 26/444 [01:20<21:33,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_763.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 27/444 [01:22<18:07,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_952.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 28/444 [01:24<17:14,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_167.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/444 [01:26<15:45,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_708.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/444 [01:27<13:33,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1245.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/444 [01:28<11:52,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_812.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 32/444 [01:29<10:57,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_76.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 33/444 [01:31<11:03,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1296.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/444 [01:33<12:02,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_239.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 35/444 [01:34<10:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_668.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 36/444 [01:36<10:42,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 37/444 [01:37<10:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_289.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 38/444 [01:39<10:50,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_45.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 39/444 [01:45<20:02,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_657.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 40/444 [01:47<17:51,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_876.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 41/444 [01:49<16:33,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1069.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 42/444 [01:53<18:59,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1318.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 43/444 [01:54<16:01,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_832.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 44/444 [01:55<13:35,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_917.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 45/444 [02:08<35:05,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_802.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 46/444 [02:10<28:38,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_275.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 47/444 [02:12<23:41,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_940.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 48/444 [02:15<21:49,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1120.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 49/444 [02:16<17:15,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_535.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 50/444 [02:17<14:26,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_244.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 51/444 [02:19<13:16,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1134.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 52/444 [02:20<11:54,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_724.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 53/444 [02:35<38:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_965.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 54/444 [02:37<30:16,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1031.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 55/444 [02:38<23:16,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1326.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 56/444 [02:40<20:14,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1325.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 57/444 [02:42<16:50,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_273.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 58/444 [02:44<15:28,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1298.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 59/444 [02:45<13:01,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_868.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 60/444 [02:46<12:02,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_964.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 61/444 [02:49<14:30,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_85.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 62/444 [02:51<12:43,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_919.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 63/444 [02:53<12:19,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_303.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 64/444 [02:57<16:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_345.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 65/444 [02:58<13:30,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_930.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 66/444 [02:59<11:46,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_817.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 67/444 [03:00<09:57,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1104.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 68/444 [03:01<09:02,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_836.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 69/444 [03:03<09:15,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_946.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 70/444 [03:04<08:31,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1312.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 71/444 [03:06<10:18,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_324.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 72/444 [03:07<09:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_913.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 73/444 [03:09<09:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_399.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 74/444 [03:10<08:24,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_766.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 75/444 [03:11<08:55,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_748.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 76/444 [03:13<09:29,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1114.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 77/444 [03:15<09:03,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1251.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 78/444 [03:16<08:20,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_59.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 79/444 [03:18<09:57,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_889.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 80/444 [03:19<08:55,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_130.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 81/444 [03:20<08:42,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_297.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 82/444 [03:22<08:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_744.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 83/444 [03:23<07:42,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_779.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 84/444 [03:24<08:29,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1210.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 85/444 [03:26<08:17,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_680.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 86/444 [03:27<07:43,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_944.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 87/444 [03:27<06:37,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 88/444 [03:29<06:36,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1057.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 89/444 [03:30<06:35,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_722.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 90/444 [03:30<05:53,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1036.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 91/444 [03:33<07:48,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_760.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 92/444 [03:34<07:52,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_675.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 93/444 [03:36<08:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_62.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 94/444 [03:37<09:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_865.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 95/444 [03:39<09:23,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_654.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 96/444 [03:43<13:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_743.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 97/444 [03:45<12:16,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_950.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 98/444 [03:46<10:06,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_77.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 99/444 [03:47<09:43,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_916.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 100/444 [03:48<08:56,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1028.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 101/444 [03:50<08:21,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_727.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 102/444 [03:51<08:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_146.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 103/444 [04:10<37:35,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_642.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 104/444 [04:10<27:01,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1313.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 105/444 [04:12<21:41,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1208.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 106/444 [04:14<17:56,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_640.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 107/444 [04:15<14:07,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_778.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 108/444 [04:16<12:38,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1025.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 109/444 [04:20<14:40,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_939.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 110/444 [04:21<12:09,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1216.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 111/444 [04:22<10:49,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_934.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 112/444 [04:24<10:36,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_904.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 113/444 [04:26<09:52,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1102.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 114/444 [04:27<09:34,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1150.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 115/444 [04:28<07:29,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_765.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 116/444 [04:30<08:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1117.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 117/444 [04:31<07:35,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_685.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 118/444 [04:32<07:54,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1329.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 119/444 [04:36<11:16,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_236.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 120/444 [04:37<09:51,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_90.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 121/444 [04:38<08:25,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_903.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 122/444 [04:39<08:14,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_905.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 123/444 [04:41<08:12,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_736.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 124/444 [04:43<09:17,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_886.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 125/444 [04:45<09:50,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_773.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 126/444 [04:47<09:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_43.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 127/444 [05:04<34:06,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_853.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 128/444 [05:06<26:37,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_278.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 129/444 [05:07<20:50,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_948.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 130/444 [05:09<17:10,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_869.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 131/444 [05:11<14:14,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1223.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 132/444 [05:12<12:52,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1038.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 133/444 [05:14<11:41,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_686.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 134/444 [05:16<10:29,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_346.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 135/444 [05:17<09:56,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_988.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 136/444 [05:19<09:04,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_653.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 137/444 [05:20<08:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_809.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 138/444 [05:21<07:49,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1043.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 139/444 [05:23<07:16,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_542.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 140/444 [05:24<06:58,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1106.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 141/444 [05:26<07:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_643.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 142/444 [05:27<07:28,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1333.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 143/444 [05:28<06:56,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1239.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 144/444 [05:30<07:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1264.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 145/444 [05:34<11:08,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_854.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 146/444 [05:35<09:45,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_681.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 147/444 [05:37<09:02,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_711.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 148/444 [05:38<08:32,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 149/444 [05:40<08:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_446.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 150/444 [05:41<07:33,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_827.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 151/444 [05:42<06:57,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_67.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 152/444 [05:45<08:54,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_776.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 153/444 [05:47<09:27,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_93.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 154/444 [05:48<08:16,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_677.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 155/444 [05:57<18:10,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1226.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 156/444 [05:58<14:51,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1136.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 157/444 [06:00<13:13,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_536.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 158/444 [06:02<11:30,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1247.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 159/444 [06:04<10:07,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_61.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 160/444 [06:05<09:31,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_336.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 161/444 [06:07<08:57,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_661.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 162/444 [06:09<08:40,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_788.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 163/444 [06:10<08:27,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1212.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 164/444 [06:11<07:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_813.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 165/444 [06:12<06:37,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1118.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 166/444 [06:14<06:42,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_678.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 167/444 [06:15<06:42,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_427.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 168/444 [06:21<13:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_755.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 169/444 [06:23<10:54,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_110.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 170/444 [06:24<09:24,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_859.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 171/444 [06:26<08:51,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_957.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 172/444 [06:27<08:14,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1252.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 173/444 [06:29<07:48,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1126.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 174/444 [06:30<06:59,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_699.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 175/444 [06:31<06:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1314.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 176/444 [06:32<06:06,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_794.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 177/444 [06:34<06:16,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1129.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 178/444 [06:35<05:59,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_808.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 179/444 [06:36<06:11,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_875.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 180/444 [06:38<06:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_842.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 181/444 [06:40<06:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1182.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 182/444 [06:41<06:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_848.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 183/444 [06:42<06:12,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1040.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 184/444 [06:44<06:21,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_956.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 185/444 [06:45<06:08,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_902.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 186/444 [06:46<05:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_441.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 187/444 [06:47<05:21,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_237.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 188/444 [06:49<06:32,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1290.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 189/444 [06:51<05:58,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1162.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 190/444 [06:52<05:48,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_700.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 191/444 [06:54<06:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1200.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 192/444 [06:55<06:20,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_147.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 193/444 [06:56<05:20,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_212.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 194/444 [06:57<05:10,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_168.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 195/444 [06:59<05:44,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_240.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 196/444 [07:00<05:57,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_695.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 197/444 [07:02<05:49,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_256.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 198/444 [07:18<23:54,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_443.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 199/444 [07:19<18:30,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_63.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 200/444 [07:21<14:54,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_721.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 201/444 [07:23<12:10,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_636.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 202/444 [07:24<10:11,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_870.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 203/444 [07:35<20:04,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1335.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 204/444 [07:36<16:02,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_707.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 205/444 [07:37<12:09,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_581.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 206/444 [07:39<10:34,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_272.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 207/444 [07:41<09:22,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1284.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 208/444 [07:42<08:23,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1135.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 209/444 [07:44<07:33,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1187.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 210/444 [07:46<07:20,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_480.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 211/444 [07:56<17:26,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_445.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 212/444 [08:00<16:35,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_447.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 213/444 [08:01<13:10,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1191.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 214/444 [08:03<11:17,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1266.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 215/444 [08:05<10:06,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1307.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 216/444 [08:06<08:36,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_270.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 217/444 [08:08<08:01,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1032.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 218/444 [08:10<07:32,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_931.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 219/444 [08:11<06:54,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_71.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 220/444 [08:12<05:58,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_482.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 221/444 [08:14<05:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_725.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 222/444 [08:15<05:40,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_301.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 223/444 [08:17<05:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_184.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 224/444 [08:19<05:43,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_387.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 225/444 [08:20<05:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_730.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 226/444 [08:22<05:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_980.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 227/444 [08:23<05:39,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_602.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 228/444 [08:26<06:26,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_874.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 229/444 [08:28<06:39,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1148.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 230/444 [08:29<06:20,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_954.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 231/444 [08:31<06:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_185.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 232/444 [08:33<06:37,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 233/444 [08:34<05:53,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_241.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 234/444 [08:36<06:10,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_697.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 235/444 [08:38<05:52,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_548.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 236/444 [08:39<05:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1128.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 237/444 [08:42<06:58,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_582.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 238/444 [08:49<12:34,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_925.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 239/444 [08:51<10:30,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_69.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 240/444 [08:52<08:37,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_896.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 241/444 [08:56<09:20,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 242/444 [08:57<08:18,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_611.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 243/444 [09:13<21:22,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_82.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 244/444 [09:14<16:03,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_591.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 245/444 [09:16<12:49,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_674.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 246/444 [09:17<10:13,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_753.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 247/444 [09:19<08:53,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_131.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 248/444 [09:21<08:04,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1103.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 249/444 [09:23<07:38,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_961.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 250/444 [09:25<07:01,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_188.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 251/444 [09:26<05:52,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_926.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 252/444 [09:30<07:58,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_921.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 253/444 [09:31<07:13,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_955.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 254/444 [09:32<05:59,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_127.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 255/444 [09:34<05:37,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_327.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 256/444 [09:36<05:32,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_485.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 257/444 [09:37<04:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_705.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 258/444 [09:39<04:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1147.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 259/444 [09:51<14:33,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_468.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 260/444 [09:53<12:10,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_477.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 261/444 [09:54<09:31,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_395.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 262/444 [09:55<07:58,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1065.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 263/444 [09:58<07:35,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_254.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 264/444 [10:01<08:41,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1017.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 265/444 [10:03<07:35,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1196.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 266/444 [10:05<06:35,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_358.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 267/444 [10:11<10:25,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_716.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 268/444 [10:12<08:11,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1236.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 269/444 [10:14<07:12,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_807.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 270/444 [10:16<06:27,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_490.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 271/444 [10:17<05:29,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_492.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 272/444 [10:18<05:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_469.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 273/444 [10:19<03:59,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_890.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 274/444 [10:20<04:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_600.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 275/444 [10:22<04:08,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_731.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 276/444 [10:28<08:12,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_339.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 277/444 [10:30<06:55,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_909.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 278/444 [10:31<05:59,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_658.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 279/444 [10:36<08:34,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_117.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 280/444 [10:40<08:38,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1082.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 281/444 [10:44<09:35,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_291.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 282/444 [10:46<08:14,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1066.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 283/444 [10:58<15:26,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_630.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 284/444 [11:00<12:00,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_404.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 285/444 [11:01<09:40,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_334.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 286/444 [11:03<08:11,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_33.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 287/444 [11:05<07:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_186.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 288/444 [11:06<05:57,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_693.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 289/444 [11:08<05:28,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_937.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 290/444 [11:10<05:13,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_424.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 291/444 [11:19<10:37,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1262.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 292/444 [11:21<08:37,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_624.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 293/444 [11:22<06:59,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_620.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 294/444 [11:27<08:35,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_142.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 295/444 [11:33<10:42,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_259.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 296/444 [11:35<08:38,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_503.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 297/444 [11:37<07:25,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1125.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 298/444 [11:39<06:43,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1332.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 299/444 [11:41<06:13,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_52.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 300/444 [11:42<04:57,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_558.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 301/444 [11:48<07:57,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_223.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 302/444 [11:50<06:35,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_194.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 303/444 [11:52<06:06,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_362.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 304/444 [12:04<12:58,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1153.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 305/444 [12:05<09:25,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_200.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 306/444 [12:07<07:51,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_479.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 307/444 [12:09<06:48,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_455.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 308/444 [12:13<07:34,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_313.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 309/444 [12:25<13:30,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 310/444 [12:27<10:41,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1100.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 311/444 [12:29<08:39,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_80.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 312/444 [12:30<06:58,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_887.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 313/444 [12:32<06:04,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_105.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 314/444 [12:34<05:03,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_483.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 315/444 [12:36<04:51,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_796.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 316/444 [12:37<04:26,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 317/444 [12:38<03:29,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_317.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 318/444 [12:39<02:53,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_963.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 319/444 [12:40<02:46,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_123.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 320/444 [13:01<15:16,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1272.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 321/444 [13:03<11:39,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_315.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 322/444 [13:26<22:14, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1202.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 323/444 [13:28<16:21,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1008.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 324/444 [13:29<11:59,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_787.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 325/444 [13:30<09:11,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1274.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 326/444 [13:32<07:31,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_265.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 327/444 [13:38<08:16,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1268.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 328/444 [13:39<06:39,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_526.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 329/444 [13:40<05:16,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1285.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 330/444 [13:42<04:26,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_460.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 331/444 [13:43<04:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_696.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 332/444 [13:44<03:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_44.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 333/444 [13:59<10:27,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_478.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 334/444 [14:21<19:12, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_450.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 335/444 [14:22<14:05,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1164.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 336/444 [14:31<14:36,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_245.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 337/444 [14:32<10:44,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_255.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 338/444 [14:49<16:18,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_513.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 339/444 [15:00<17:16,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_504.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 340/444 [15:15<19:36, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_590.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 341/444 [15:17<14:31,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_592.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 342/444 [15:18<10:43,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_389.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 343/444 [15:19<07:49,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_353.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 344/444 [15:20<06:07,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_250.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 345/444 [15:24<06:15,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_432.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 346/444 [15:26<05:02,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_583.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 347/444 [15:28<04:27,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_402.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 348/444 [15:29<03:40,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_312.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 349/444 [15:31<03:28,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_493.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 350/444 [15:32<02:58,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_516.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 351/444 [15:34<02:59,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_373.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 352/444 [15:54<11:26,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_119.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 353/444 [15:56<08:43,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1175.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 354/444 [15:58<06:57,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1160.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 355/444 [16:16<12:40,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_102.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 356/444 [16:18<09:39,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_140.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 357/444 [16:19<07:22,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_205.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 358/444 [16:21<05:45,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_414.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 359/444 [16:30<07:56,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_314.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 360/444 [16:32<06:18,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_374.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 361/444 [16:35<05:17,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1177.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 362/444 [16:36<04:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_464.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 363/444 [16:48<07:49,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_518.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 364/444 [17:12<14:58, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_352.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 365/444 [17:14<11:14,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_396.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 366/444 [17:15<08:19,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_332.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 367/444 [17:18<06:34,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_495.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 368/444 [17:20<05:16,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 369/444 [17:37<10:02,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_463.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 370/444 [17:55<13:50, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_970.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 371/444 [17:57<10:01,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_120.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 372/444 [17:59<07:47,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_293.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 373/444 [18:01<06:01,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_688.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 374/444 [18:03<04:52,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_834.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 375/444 [18:05<04:01,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_440.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 376/444 [18:08<03:53,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_116.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 377/444 [18:09<03:01,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_359.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 378/444 [18:27<08:07,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 379/444 [18:30<06:22,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_154.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 380/444 [18:48<10:11,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 381/444 [18:49<07:29,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_413.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 382/444 [19:01<08:52,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1075.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 383/444 [19:04<06:48,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_163.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 384/444 [19:05<05:11,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1171.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 385/444 [19:07<04:03,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_745.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 386/444 [19:19<06:18,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_527.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 387/444 [19:21<04:53,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_202.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 388/444 [19:23<03:52,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_533.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 389/444 [19:25<03:13,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_226.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 390/444 [19:26<02:38,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_552.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 391/444 [19:28<02:14,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_978.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 392/444 [19:41<05:01,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_994.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 393/444 [19:43<03:55,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_365.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 394/444 [19:45<03:11,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1185.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 395/444 [19:47<02:36,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_826.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 396/444 [19:49<02:09,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_860.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 397/444 [19:50<01:51,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_23.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 398/444 [19:52<01:42,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_144.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 399/444 [19:56<02:03,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_586.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 400/444 [20:15<05:41,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_489.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 401/444 [20:18<04:25,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_694.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 402/444 [20:20<03:23,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_704.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 403/444 [20:27<03:51,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_783.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 404/444 [20:29<03:02,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1059.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 405/444 [20:34<03:04,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_549.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 406/444 [20:36<02:24,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_627.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 407/444 [20:38<01:58,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_311.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 408/444 [20:40<01:39,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_118.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 409/444 [20:41<01:18,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_462.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 410/444 [20:43<01:14,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_419.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 411/444 [20:45<01:13,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_983.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 412/444 [20:52<01:54,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1172.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 413/444 [20:54<01:35,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_436.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 414/444 [20:55<01:21,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_687.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 415/444 [20:57<01:06,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_514.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 416/444 [20:59<01:03,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_484.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 417/444 [21:01<00:58,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1131.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 418/444 [21:03<00:52,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 419/444 [21:29<03:55,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_547.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 420/444 [21:31<02:53,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_652.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 421/444 [21:32<02:03,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_703.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 422/444 [21:34<01:32,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 423/444 [21:35<01:07,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_563.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 424/444 [21:37<00:59,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1078.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 425/444 [21:49<01:48,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_758.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 426/444 [21:51<01:23,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_647.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 427/444 [21:53<01:03,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_867.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 428/444 [21:55<00:52,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_567.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 429/444 [21:57<00:41,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_471.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 430/444 [22:00<00:38,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_576.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 431/444 [22:01<00:29,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_210.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 432/444 [22:10<00:53,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_993.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 433/444 [22:18<00:59,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_390.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 434/444 [22:22<00:49,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_104.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 435/444 [22:35<01:05,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_366.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 436/444 [22:43<01:01,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_990.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 437/444 [22:45<00:41,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1099.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 438/444 [22:47<00:28,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_609.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 439/444 [23:06<00:45,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_494.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 440/444 [23:08<00:27,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_363.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 441/444 [23:09<00:15,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_481.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 442/444 [23:11<00:08,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_989.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 443/444 [23:28<00:07,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing: c:/Users/HARSHAL/Downloads/SHL Research Intern Assignment/dataset/audios_train/audio_1163.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 444/444 [23:30<00:00,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved transcripts to outputs/transcripts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"dataset/train.csv\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    filename = row[\"filename\"].strip()\n",
    "    label = row[\"label\"]\n",
    "    \n",
    "    # Use raw string + absolute path to avoid ffmpeg issues\n",
    "    file_path = os.path.abspath(os.path.join(\"dataset\", \"audios_train\", filename))\n",
    "    file_path = file_path.replace(\"\\\\\", \"/\")  # Force forward slashes (ffmpeg safe)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"🎧 Transcribing: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        result = model.transcribe(file_path, language=\"en\")\n",
    "        transcript = result[\"text\"]\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"transcript\": transcript,\n",
    "            \"label\": label\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error on {filename}: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "pd.DataFrame(results).to_csv(\"outputs/transcripts.csv\", index=False)\n",
    "print(\"✅ Saved transcripts to outputs/transcripts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>label</th>\n",
       "      <th>grammar_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_1261.wav</td>\n",
       "      <td>I'm going to put it on the top of the head. I...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_942.wav</td>\n",
       "      <td>The playground looks like very clear and neat...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_1110.wav</td>\n",
       "      <td>My goal is to become an electrical employee a...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_1024.wav</td>\n",
       "      <td>My favorite place is in Andhra Pradesh. It is...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_538.wav</td>\n",
       "      <td>My favorite places, my favorite places, Mutti...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                         transcript  label  \\\n",
       "0  audio_1261.wav   I'm going to put it on the top of the head. I...    1.0   \n",
       "1   audio_942.wav   The playground looks like very clear and neat...    1.5   \n",
       "2  audio_1110.wav   My goal is to become an electrical employee a...    1.5   \n",
       "3  audio_1024.wav   My favorite place is in Andhra Pradesh. It is...    1.5   \n",
       "4   audio_538.wav   My favorite places, my favorite places, Mutti...    2.0   \n",
       "\n",
       "   grammar_score  \n",
       "0            3.0  \n",
       "1            3.0  \n",
       "2            3.0  \n",
       "3            3.0  \n",
       "4            3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"outputs/grammar_scores.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"outputs/grammar_scores.csv\")\n",
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer([examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscript\u001b[39m\u001b[38;5;124m\"\u001b[39m]], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Apply the tokenization to the dataset\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(tokenize_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\")\n",
    "# Define the tokenization function\n",
    "def tokenize_function(examples):\n",
    "    # Ensure 'transcript' is a list of strings\n",
    "    if isinstance(examples[\"transcript\"], list):\n",
    "        return tokenizer(examples[\"transcript\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    else:\n",
    "        # If it's not a list of strings, convert it into one\n",
    "        return tokenizer([examples[\"transcript\"]], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Apply the tokenization to the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Apply dynamic quantization (this reduces memory usage by converting weights to INT8)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_dynamic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Model to quantize\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Quantize all Linear layers (this is common for most models)\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqint8\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use INT8 for the weights\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Ensure the model is set to output hidden states\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\ao\\quantization\\quantize.py:559\u001b[0m, in \u001b[0;36mquantize_dynamic\u001b[1;34m(model, qconfig_spec, dtype, mapping, inplace)\u001b[0m\n\u001b[0;32m    556\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m get_default_dynamic_quant_module_mappings()\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m--> 559\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    561\u001b[0m propagate_qconfig_(model, qconfig_spec)\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:259\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 259\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    261\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:259\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 259\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    261\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[1;31m[... skipping similar frames: _deepcopy_dict at line 221 (8 times), deepcopy at line 136 (8 times), _reconstruct at line 259 (3 times), deepcopy at line 162 (3 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:259\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 259\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    261\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[1;31m[... skipping similar frames: _deepcopy_dict at line 221 (1 times), deepcopy at line 136 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:143\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    141\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\parameter.py:68\u001b[0m, in \u001b[0;36mParameter.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\n\u001b[1;32m---> 68\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     70\u001b[0m     memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if a GPU is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(\"outputs/grammar_scores.csv\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Apply dynamic quantization (this reduces memory usage by converting weights to INT8)\n",
    "model = torch.quantization.quantize_dynamic(\n",
    "    model,  # Model to quantize\n",
    "    {torch.nn.Linear},  # Quantize all Linear layers (this is common for most models)\n",
    "    dtype=torch.qint8  # Use INT8 for the weights\n",
    ")\n",
    "\n",
    "# Ensure the model is set to output hidden states\n",
    "model.config.output_hidden_states = True\n",
    "\n",
    "# Function to clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def get_embedding(text):\n",
    "    # Tokenize the input text and move it to GPU if available\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)  # Reduced max_length\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move to GPU\n",
    "\n",
    "    # Check if tokens are valid\n",
    "    if not inputs[\"input_ids\"].any():\n",
    "        print(f\"Empty tokenization for text: {text}\")\n",
    "        return [0] * 768\n",
    "\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # Use mixed precision (FP16) if possible\n",
    "            with torch.cuda.amp.autocast():  # Enables FP16 on supported GPUs\n",
    "                outputs = model(**inputs)\n",
    "        except RuntimeError as e:\n",
    "            if 'out of memory' in str(e):\n",
    "                print(\"Out of memory error. Trying to clear cache and continue...\")\n",
    "                clear_gpu_memory()  # Clear GPU memory cache and retry\n",
    "                return get_embedding(text)  # Retry the operation\n",
    "        \n",
    "    # Use model's hidden states to extract embeddings\n",
    "    hidden_states = outputs.hidden_states  # This should contain the hidden states at each layer\n",
    "\n",
    "    if hidden_states is None:\n",
    "        print(f\"Hidden states not found for text: {text}\")\n",
    "        return [0] * 768\n",
    "\n",
    "    # Get the last hidden state\n",
    "    last_hidden_state = hidden_states[-1]  # Last hidden state from the last transformer layer\n",
    "    \n",
    "    # Mean over all token embeddings to get a single vector for the input\n",
    "    embeddings = last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "    # Check if embeddings are valid\n",
    "    if embeddings is None or not embeddings.any():\n",
    "        print(f\"Invalid embeddings for text: {text}\")\n",
    "        return [0] * 768\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Get embeddings for all transcripts\n",
    "embeddings = []\n",
    "for t in tqdm(df[\"transcript\"]):\n",
    "    try:\n",
    "        emb = get_embedding(t)\n",
    "        embeddings.append(emb)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing transcript: {e}\")\n",
    "        embeddings.append([0] * 768)\n",
    "\n",
    "# Convert to DataFrame\n",
    "emb_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(768)])\n",
    "final_df = pd.concat([df.reset_index(drop=True), emb_df], axis=1)\n",
    "final_df.to_csv(\"outputs/train_features_full.csv\", index=False)\n",
    "print(\"✅ Embeddings + grammar features saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model proper working or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Predicted Grammar Score: 3.00\n",
      "✅ Actual Grammar Score   : 3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load saved model\n",
    "model = joblib.load(\"outputs/grammar_scorer.pkl\")\n",
    "\n",
    "# Load sample input features (same format as training)\n",
    "df = pd.read_csv(\"outputs/train_features_full.csv\")\n",
    "\n",
    "# Select embedding feature columns\n",
    "feature_cols = [col for col in df.columns if col.startswith('emb_')]\n",
    "if not feature_cols:\n",
    "    raise ValueError(\"No embedding columns found in the dataset\")\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Predict grammar score for 1st sample\n",
    "sample_index = 0\n",
    "sample = X.iloc[sample_index:sample_index+1]  # Keep shape (1, n_features)\n",
    "\n",
    "pred_score = model.predict(sample)[0]\n",
    "true_score = df[\"grammar_score\"].iloc[sample_index]\n",
    "\n",
    "print(f\"🎯 Predicted Grammar Score: {pred_score:.2f}\")\n",
    "print(f\"✅ Actual Grammar Score   : {true_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎤 Input Sentence: \"People in the market are selling just about anything and everything. You can hear everyone screaming and talking over each other, making offers. The crowded market scene makes me want to run out of the door as soon as possible, and I picture this happening midday.\"\n",
      "📊 Predicted Grammar Score: 3.16 / 5.0\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import language_tool_python\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Load models\n",
    "model = joblib.load(\"outputs/grammar_scorer.pkl\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "bert_model = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "bert_model.eval()\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Input text and corresponding audio\n",
    "text = \"People in the market are selling just about anything and everything. You can hear everyone screaming and talking over each other, making offers. The crowded market scene makes me want to run out of the door as soon as possible, and I picture this happening midday.\"\n",
    "audio_path = \"dataset/audios_train/audio_2.wav\"  # Update with your real file path\n",
    "\n",
    "# --- Text-based Features ---\n",
    "words = text.split()\n",
    "num_words = len(words)\n",
    "avg_word_len = sum(len(word) for word in words) / num_words\n",
    "text_length = len(text)\n",
    "\n",
    "matches = tool.check(text)\n",
    "num_errors = len(matches)\n",
    "grammar_ratio = num_errors / max(num_words, 1)\n",
    "\n",
    "grammar_features = pd.DataFrame({\n",
    "    \"num_words\": [num_words],\n",
    "    \"num_errors\": [num_errors],\n",
    "    \"grammar_ratio\": [grammar_ratio],\n",
    "    \"avg_word_len\": [avg_word_len],\n",
    "    \"text_length\": [text_length]\n",
    "})\n",
    "\n",
    "# --- DeBERTa Embeddings ---\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(**inputs)\n",
    "embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "embedding_df = pd.DataFrame([embedding], columns=[f\"emb_{i}\" for i in range(len(embedding))])\n",
    "\n",
    "# --- Audio-based Features ---\n",
    "y, sr = librosa.load(audio_path)\n",
    "duration = librosa.get_duration(y=y, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
    "centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
    "rmse = librosa.feature.rms(y=y).mean()\n",
    "\n",
    "audio_features = pd.DataFrame({\n",
    "    \"duration\": [duration],\n",
    "    \"zero_crossing_rate\": [zcr],\n",
    "    \"spectral_centroid\": [centroid],\n",
    "    \"rmse\": [rmse]\n",
    "})\n",
    "\n",
    "# Optional placeholder for ensemble or second model output\n",
    "grammar_score_model = 0  # Set to 0 or your sub-model output if any\n",
    "model_output_feature = pd.DataFrame({\"grammar_score_model\": [grammar_score_model]})\n",
    "\n",
    "# --- Combine All ---\n",
    "final_input = pd.concat([grammar_features, audio_features, model_output_feature, embedding_df], axis=1)\n",
    "\n",
    "# --- Match training columns order ---\n",
    "try:\n",
    "    final_input = final_input[model.feature_names_in_]\n",
    "except AttributeError:\n",
    "    print(\"⚠️ 'feature_names_in_' not found. Skipping reorder. Ensure column order is same as during training.\")\n",
    "\n",
    "# --- Predict Grammar Score ---\n",
    "pred_score = model.predict(final_input)[0]\n",
    "\n",
    "# --- Output ---\n",
    "print(f\"\\n🎤 Input Sentence: \\\"{text}\\\"\")\n",
    "print(f\"📊 Predicted Grammar Score: {pred_score:.2f} / 5.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎤 Input Sentence: \"People in the market are selling just about anything and everything. You can hear everyone screaming and talking over each other, making offers. The crowded market scene makes me want to run out of the door as soon as possible, and I picture this happening midday.\"\n",
      "📊 Predicted Grammar Score: 3.80 / 5.0\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import language_tool_python\n",
    "import numpy as np\n",
    "\n",
    "# Load your trained model\n",
    "model = joblib.load(\"outputs/grammar_scorer.pkl\")\n",
    "\n",
    "# Load tokenizer and DeBERTa model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "bert_model = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "bert_model.eval()\n",
    "\n",
    "# Grammar tool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Input sentence (text only)\n",
    "text = \"People in the market are selling just about anything and everything. You can hear everyone screaming and talking over each other, making offers. The crowded market scene makes me want to run out of the door as soon as possible, and I picture this happening midday.\"\n",
    "\n",
    "# Text-based features\n",
    "words = text.split()\n",
    "num_words = len(words)\n",
    "avg_word_len = sum(len(w) for w in words) / num_words\n",
    "text_length = len(text)\n",
    "\n",
    "matches = tool.check(text)\n",
    "num_errors = len(matches)\n",
    "grammar_ratio = num_errors / max(num_words, 1)\n",
    "\n",
    "grammar_features = pd.DataFrame({\n",
    "    \"num_words\": [num_words],\n",
    "    \"num_errors\": [num_errors],\n",
    "    \"grammar_ratio\": [grammar_ratio],\n",
    "    \"avg_word_len\": [avg_word_len],\n",
    "    \"text_length\": [text_length]\n",
    "})\n",
    "\n",
    "# DeBERTa embeddings\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(**inputs)\n",
    "embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "embedding_df = pd.DataFrame([embedding], columns=[f\"emb_{i}\" for i in range(len(embedding))])\n",
    "\n",
    "# Dummy audio features since no audio is present\n",
    "audio_features = pd.DataFrame({\n",
    "    \"duration\": [0.0],\n",
    "    \"zero_crossing_rate\": [0.0],\n",
    "    \"spectral_centroid\": [0.0],\n",
    "    \"rmse\": [0.0]\n",
    "})\n",
    "\n",
    "# Dummy ensemble or sub-model feature\n",
    "model_output_feature = pd.DataFrame({\"grammar_score_model\": [0.0]})\n",
    "\n",
    "# Combine all features\n",
    "final_input = pd.concat([grammar_features, audio_features, model_output_feature, embedding_df], axis=1)\n",
    "\n",
    "# Match training feature order\n",
    "try:\n",
    "    final_input = final_input[model.feature_names_in_]\n",
    "except AttributeError:\n",
    "    print(\"⚠️ 'feature_names_in_' not available. Ensure feature order manually matches training data.\")\n",
    "\n",
    "# Predict score\n",
    "pred_score = model.predict(final_input)[0]\n",
    "\n",
    "# Output result\n",
    "print(f\"\\n🎤 Input Sentence: \\\"{text}\\\"\")\n",
    "print(f\"📊 Predicted Grammar Score: {pred_score:.2f} / 5.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['duration', 'zero_crossing_rate', 'spectral_centroid', 'rmse', 'grammar_score_model', 'num_words', 'avg_word_len', 'text_length'] ['duration', 'zero_crossing_rate', 'spectral_centroid', 'rmse', 'num_words', 'avg_word_len', 'text_length']\nexpected grammar_score_model in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([features])\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m predicted_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🎯 Hybrid Model Grammar Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🧠 Predicted Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1327\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1336\u001b[0m             cp \u001b[38;5;241m=\u001b[39m import_cupy()\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2667\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2665\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2667\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2669\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Users\\HARSHAL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:3243\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3238\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3240\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3241\u001b[0m     )\n\u001b[1;32m-> 3243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['duration', 'zero_crossing_rate', 'spectral_centroid', 'rmse', 'grammar_score_model', 'num_words', 'avg_word_len', 'text_length'] ['duration', 'zero_crossing_rate', 'spectral_centroid', 'rmse', 'num_words', 'avg_word_len', 'text_length']\nexpected grammar_score_model in input data"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import language_tool_python\n",
    "import pickle\n",
    "\n",
    "# Load the trained hybrid model\n",
    "with open(\"hybrid_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Setup grammar checker\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Audio feature extraction (limited to used features)\n",
    "def extract_audio_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    return {\n",
    "        \"duration\": librosa.get_duration(y=y, sr=sr),\n",
    "        \"zero_crossing_rate\": np.mean(librosa.feature.zero_crossing_rate(y)),\n",
    "        \"spectral_centroid\": np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
    "        \"rmse\": np.mean(librosa.feature.rms(y=y))\n",
    "    }\n",
    "\n",
    "# Text feature extraction (limited to used features)\n",
    "def extract_text_features(text):\n",
    "    words = text.split()\n",
    "    return {\n",
    "        \"num_words\": len(words),\n",
    "        \"avg_word_len\": sum(len(w) for w in words) / max(len(words), 1),\n",
    "        \"text_length\": len(text)\n",
    "    }\n",
    "\n",
    "# Combine features in correct order\n",
    "def extract_combined_features(audio_path, transcript):\n",
    "    audio_feats = extract_audio_features(audio_path)\n",
    "    text_feats = extract_text_features(transcript)\n",
    "    return {\n",
    "        \"duration\": audio_feats[\"duration\"],\n",
    "        \"zero_crossing_rate\": audio_feats[\"zero_crossing_rate\"],\n",
    "        \"spectral_centroid\": audio_feats[\"spectral_centroid\"],\n",
    "        \"rmse\": audio_feats[\"rmse\"],\n",
    "        \"num_words\": text_feats[\"num_words\"],\n",
    "        \"avg_word_len\": text_feats[\"avg_word_len\"],\n",
    "        \"text_length\": text_feats[\"text_length\"]\n",
    "    }\n",
    "\n",
    "# === Input test sample ===\n",
    "audio_path = \"dataset/audios_train/audio_2.wav\"\n",
    "transcript = \"\"\"People in the market are selling just about anything and everything. \n",
    "You can hear everyone screaming and talking over each other, making offers. \n",
    "The crowded market scene makes me want to run out of the door as soon as possible, and I picture this happening midday.\"\"\"\n",
    "\n",
    "# Extract features and predict\n",
    "features = extract_combined_features(audio_path, transcript)\n",
    "df = pd.DataFrame([features])\n",
    "\n",
    "# Predict using the model\n",
    "predicted_score = model.predict(df)[0]\n",
    "\n",
    "print(\"\\n🎯 Hybrid Model Grammar Score:\")\n",
    "print(f\"🧠 Predicted Score: {predicted_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final test of the model hybrid_mode.pkl and grammar_scorer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎧 Transcript: People in the market are selling just about anything and everything. You can hear everyone screaming and talking over each other, making offers.\n",
      "🔊 Hybrid model score: 3.41\n",
      "📘 Grammar model score: 3.51\n",
      "✅ Final predicted grammar score: 3.46 / 5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "import joblib\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import language_tool_python\n",
    "\n",
    "# === Paths to models ===\n",
    "GRAMMAR_MODEL_PATH = \"outputs/grammar_scorer.pkl\"\n",
    "HYBRID_MODEL_PATH = \"hybrid_model_cpu.pkl\"\n",
    "\n",
    "# === Load models ===\n",
    "grammar_model = joblib.load(GRAMMAR_MODEL_PATH)\n",
    "with open(HYBRID_MODEL_PATH, \"rb\") as f:\n",
    "    hybrid_model = pickle.load(f)\n",
    "\n",
    "# === Load tokenizer and DeBERTa model ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "bert_model = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "bert_model.eval()\n",
    "\n",
    "# === LanguageTool for grammar checking ===\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# === Feature extraction functions ===\n",
    "def extract_audio_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    return {\n",
    "        \"duration\": librosa.get_duration(y=y, sr=sr),\n",
    "        \"zero_crossing_rate\": np.mean(librosa.feature.zero_crossing_rate(y)),\n",
    "        \"spectral_centroid\": np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
    "        \"rmse\": np.mean(librosa.feature.rms(y=y))\n",
    "    }\n",
    "\n",
    "def extract_text_features(text):\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    avg_word_len = sum(len(w) for w in words) / max(num_words, 1)\n",
    "    text_length = len(text)\n",
    "    matches = tool.check(text)\n",
    "    num_errors = len(matches)\n",
    "    grammar_ratio = num_errors / max(num_words, 1)\n",
    "    \n",
    "    return {\n",
    "        \"num_words\": num_words,\n",
    "        \"avg_word_len\": avg_word_len,\n",
    "        \"text_length\": text_length,\n",
    "        \"num_errors\": num_errors,\n",
    "        \"grammar_ratio\": grammar_ratio\n",
    "    }\n",
    "\n",
    "def get_deberta_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "# === Predict grammar score ===\n",
    "def predict_score(audio_path, transcript):\n",
    "    # --- Hybrid model (audio + basic text) ---\n",
    "    audio_feats = extract_audio_features(audio_path)\n",
    "    text_feats = extract_text_features(transcript)\n",
    "    hybrid_input = pd.DataFrame([{**audio_feats, **{k: text_feats[k] for k in ['num_words', 'avg_word_len', 'text_length']}}])\n",
    "\n",
    "    try:\n",
    "        hybrid_input = hybrid_input[hybrid_model.feature_names_in_]\n",
    "    except:\n",
    "        pass  # Optional: enforce manual column matching if needed\n",
    "    \n",
    "    hybrid_pred = hybrid_model.predict(hybrid_input)[0]\n",
    "\n",
    "    # --- Grammar model (text + embedding + grammar stats) ---\n",
    "    grammar_feats = pd.DataFrame([{\n",
    "        \"num_words\": text_feats[\"num_words\"],\n",
    "        \"num_errors\": text_feats[\"num_errors\"],\n",
    "        \"grammar_ratio\": text_feats[\"grammar_ratio\"],\n",
    "        \"avg_word_len\": text_feats[\"avg_word_len\"],\n",
    "        \"text_length\": text_feats[\"text_length\"],\n",
    "        \"duration\": audio_feats[\"duration\"],  # dummy/filler to match training input\n",
    "        \"zero_crossing_rate\": audio_feats[\"zero_crossing_rate\"],\n",
    "        \"spectral_centroid\": audio_feats[\"spectral_centroid\"],\n",
    "        \"rmse\": audio_feats[\"rmse\"],\n",
    "        \"grammar_score_model\": hybrid_pred  # feedback loop\n",
    "    }])\n",
    "\n",
    "    emb = get_deberta_embedding(transcript)\n",
    "    emb_df = pd.DataFrame([emb], columns=[f\"emb_{i}\" for i in range(len(emb))])\n",
    "    grammar_input = pd.concat([grammar_feats, emb_df], axis=1)\n",
    "\n",
    "    try:\n",
    "        grammar_input = grammar_input[grammar_model.feature_names_in_]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    grammar_pred = grammar_model.predict(grammar_input)[0]\n",
    "\n",
    "    # === Combine predictions (simple average) ===\n",
    "    final_score = (hybrid_pred + grammar_pred) / 2\n",
    "\n",
    "    # === Output ===\n",
    "    print(\"\\n🎧 Transcript:\", transcript)\n",
    "    print(f\"🔊 Hybrid model score: {hybrid_pred:.2f}\")\n",
    "    print(f\"📘 Grammar model score: {grammar_pred:.2f}\")\n",
    "    print(f\"✅ Final predicted grammar score: {final_score:.2f} / 5.0\")\n",
    "\n",
    "# === Test it ===\n",
    "# Change these with your sample audio + transcript\n",
    "sample_audio = \"dataset/audios_train/audio_2.wav\"\n",
    "sample_transcript = \"People in the market are selling just about anything and everything. You can hear everyone screaming and talking over each other, making offers.\"\n",
    "\n",
    "predict_score(sample_audio, sample_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/grammar_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         filename                                         transcript  \\\n",
       " 0   audio_706.wav   A market place is an exceptionally bustling s...   \n",
       " 1   audio_800.wav   My favorite hobby is reading, I love getting ...   \n",
       " 2    audio_68.wav   Yeah, I have a soy crowded market. There are ...   \n",
       " 3  audio_1267.wav   My favorite hobby is writing. I have a flip f...   \n",
       " 4   audio_683.wav   Okay, in a product market, basically, I have ...   \n",
       " \n",
       "    grammar_score                                     corrected_text  \n",
       " 0       4.011839  The market is an exceptionally bustling spot w...  \n",
       " 1       3.954985  My favorite hobby is reading, I love getting l...  \n",
       " 2       3.603638  Yeah, I have a very crowded market. There are ...  \n",
       " 3       3.579485  I enjoy writing because it helps me to express...  \n",
       " 4       4.072959  Okay, in a product market, basically, I have a...  ,\n",
       " Index(['filename', 'transcript', 'grammar_score', 'corrected_text'], dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['transcript','corrected_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'grammar_score'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'grammar_score': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Submission_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
